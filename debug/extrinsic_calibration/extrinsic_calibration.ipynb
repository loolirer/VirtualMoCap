{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual Arena\n",
    "\n",
    "This notebook is an implementation of a virtual arena.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules...\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import cv2\n",
    "import socket\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..') # Go back to base directory\n",
    "\n",
    "from modules.plot.viewer2d import Viewer2D\n",
    "from modules.plot.viewer3d import Viewer3D\n",
    "\n",
    "from modules.vision.linear_projection import build_projection_matrix, build_extrinsic_matrix\n",
    "from modules.vision.camera import Camera\n",
    "from modules.vision.synchronizer import Synchronizer\n",
    "\n",
    "from modules.integration.client import Client\n",
    "from modules.integration.coppeliasim.server import CoppeliaSim_Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanciating `Server` and `Client` Structures\n",
    "\n",
    "To wrap the information of all clients and mediate the communication between this notebook and *CoppeliaSim*, a `Server` object will be instanciated. \n",
    "\n",
    "The `Client` objects will be generated by their camera model and a synchronizer, representing their respective twin in the simulation.\n",
    "\n",
    "For the `Server` instanciation, the following parameters must be given:\n",
    "- Server address;\n",
    "- *CoppeliaSim's* simulation Controller address;\n",
    "- List containing all the clients present in the scene.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 4 # Number of clients in the arena\n",
    "\n",
    "clients = []  # Clients list\n",
    "\n",
    "# Object matrix of Camera 0\n",
    "base_matrix = np.array([[-7.07106781e-01,  5.00000000e-01, -5.00000000e-01, 2.50000000e+00],\n",
    "                        [ 7.07106781e-01,  5.00000000e-01, -5.00000000e-01, 2.50000000e+00],\n",
    "                        [ 1.46327395e-13, -7.07106781e-01, -7.07106781e-01, 2.50000000e+00]])\n",
    "\n",
    "# Create clients\n",
    "for ID in range(n_clients):\n",
    "    # Spread all cameras uniformely in a circle around the arena\n",
    "    R = np.array(sp.spatial.transform.Rotation.from_euler('z', (360 / n_clients) * ID, degrees=True).as_matrix())\n",
    "    object_matrix_auxiliary = R @ base_matrix\n",
    "\n",
    "    # Generate associated camera model\n",
    "    camera = (Camera(# Intrinsic Parameters\n",
    "                     resolution=(1080,1080), \n",
    "                     fov_degrees=60.0,     \n",
    "    \n",
    "                     # Extrinsic Parameters\n",
    "                     object_matrix=object_matrix_auxiliary,\n",
    "    \n",
    "                     # Rational Lens Distortion Model\n",
    "                     # distortion_model='rational',\n",
    "                     # distortion_coefficients=np.array([0.014, -0.003, -0.0002, -0.000003, 0.0009, 0.05, -0.007, 0.0017]), \n",
    "                    \n",
    "                     # Fisheye Lens Distortion Model\n",
    "                     distortion_model='fisheye',\n",
    "                     distortion_coefficients=np.array([0.395, 0.633, -2.417, 2.110]),\n",
    "    \n",
    "                     # Image Noise Model\n",
    "                     snr_dB=13\n",
    "                     ))\n",
    "    \n",
    "    clients.append(Client(camera=camera))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create server\n",
    "server = CoppeliaSim_Server(clients=clients,\n",
    "                            server_address=('127.0.0.1', 8888),\n",
    "                            controller_address=('127.0.0.1', 7777))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requesting Scene\n",
    "\n",
    "A **Scene Request** will send to *CoppeliaSim* the data necessary to instanciate the simulated clients' twins in the childscripts. The scene request can be used to reset the client's data from the server if called again.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Wrapping up CoppeliaSim scene info\n",
      "[SERVER] Scene info sent\n",
      "[SERVER] Scene set!\n"
     ]
    }
   ],
   "source": [
    "# Request scene with the associated server clients\n",
    "if not server.request_scene():\n",
    "    sys.exit() # Scene request failed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requesting Capture\n",
    "\n",
    "A **Capture Request** will trigger a simulation in *CoppeliaSim* sending the total simulation time of the requested capture. Once the simulation stops, another capture request can be called for another simulation\n",
    "\n",
    "In the simulation start, the clients will be created and send their ID to the server for client registration.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Capture info sent\n",
      "[SERVER] Capture confirmed!\n",
      "[SERVER] Waiting for clients...\n",
      "\tClient 0 registered\n",
      "\tClient 1 registered\n",
      "\tClient 2 registered\n",
      "\tClient 3 registered\n",
      "[SERVER] All clients registered!\n"
     ]
    }
   ],
   "source": [
    "# Capture specifications\n",
    "blob_count = 3 # Number of expected markers\n",
    "capture_time = 120.0 # In seconds\n",
    "window = 3 # The minimum ammount of points for interpolating \n",
    "throughput = 20 # Triangulated scenes per second\n",
    "step = 1 / throughput # Interpolation timestep\n",
    "\n",
    "# Capture synchronizer\n",
    "synchronizer = Synchronizer(blob_count, window, step, capture_time)\n",
    "\n",
    "# Request capture (start simulation)\n",
    "if not server.request_capture(synchronizer):\n",
    "    sys.exit() # Capture request failed!\n",
    "\n",
    "# Wait for client identification\n",
    "server.register_clients()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Simulation\n",
    "\n",
    "The messages will be received here in the following loop until a server timeout is reached. To analyse the content of each message, toggle the `verbose` flag. \n",
    "\n",
    "The loop will wait for a message to be received by the socket. When a message comes, it will record it and wait for the next message. \n",
    "\n",
    "Since the calibration prioritizes the amount of quality data and not real time triangulation, the in-loop actions will be post-processed to avoid message losses.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Timeout set to 5 seconds\n",
      "\n",
      "\n",
      "[SERVER] Timed Out!\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "\n",
    "timeout = 5 # In seconds\n",
    "server.udp_socket.settimeout(timeout) # Set server timeout\n",
    "print(f'[SERVER] Timeout set to {timeout} seconds\\n')\n",
    "\n",
    "message_log = [[] for _ in range(n_clients)]\n",
    "\n",
    "# Breaks in the timeout\n",
    "while True: \n",
    "    # Wait for message - Event guided!\n",
    "    try:\n",
    "        message_bytes, address = server.udp_socket.recvfrom(server.buffer_size)\n",
    "\n",
    "    except socket.timeout as err:\n",
    "        print('\\n[SERVER] Timed Out!')\n",
    "        \n",
    "        break # Close capture loop due to timeout\n",
    "    \n",
    "    # Check if client exists\n",
    "    try:\n",
    "        ID = server.client_addresses[address] # Client Identifier\n",
    "    \n",
    "    except:\n",
    "        if verbose: print('> Client not recognized')\n",
    "\n",
    "        continue # Jump to wait for the next message\n",
    "    \n",
    "    # Show sender\n",
    "    if verbose: print(f'> Received message from Client {ID} ({address[0]}, {address[1]})')\n",
    "\n",
    "    # Save message in it's respective client message log\n",
    "    message_log[ID].append(message_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing Data\n",
    "\n",
    "For each client, the code will loop through it's message history and it will:\n",
    "1. Decode message; \n",
    "2. Parse the message for it's contents;\n",
    "3. Check if the message is valid;\n",
    "    - A valid message is composed of a blob coodinate and it's area (per blob) and the PTS of the message.\n",
    "4. Undistort blob data\n",
    "5. Save data in the `Synchronizer` structure.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "\n",
    "for ID, client_messages in enumerate(message_log):\n",
    "    # Parse through client's message history\n",
    "    for message_bytes in client_messages: \n",
    "\n",
    "        # Decode message\n",
    "        try:\n",
    "            message = np.frombuffer(message_bytes, dtype=np.float32)\n",
    "\n",
    "        except:\n",
    "            if verbose: print('> Couldn\\'t decode message')\n",
    "\n",
    "            continue # Jump to the next message\n",
    "\n",
    "        # Empty message\n",
    "        if not message.size:\n",
    "            if verbose: print('\\tEmpty message')\n",
    "\n",
    "            continue # Jump to the next message\n",
    "\n",
    "        # Extracting the message's PTS\n",
    "        PTS = message[-1] # Last element of the message \n",
    "\n",
    "        # Valid message is [u, v, A] per blob and the PTS of the message\n",
    "        if message.size !=  3 * blob_count + 1:\n",
    "\n",
    "            if message.size == 1: # Only PTS\n",
    "                if verbose: print(f'\\tNo blobs were detected - {PTS :.3f} s')\n",
    "\n",
    "            else: \n",
    "                if verbose: \n",
    "                    print(f'\\tWrong blob count or corrupted message')\n",
    "                    print(f'Corrupted Message: {message}')\n",
    "\n",
    "            continue # Jump to the next message\n",
    "\n",
    "        # Extracting blob data (coordinates & area)\n",
    "        sync_blobs = message[:-1].reshape(-1, 3) # All but last element (reserved for PTS)\n",
    "\n",
    "        # Extracting centroids\n",
    "        blob_centroids = sync_blobs[:,:2] # Ignoring their area\n",
    "\n",
    "        # Undistorting blobs centroids\n",
    "        undistorted_blobs = server.clients[ID].camera.undistort_points(blob_centroids)          \n",
    "\n",
    "        # Print blobs\n",
    "        if verbose:\n",
    "            print(f'\\tDetected Blobs - {PTS :.3f} s')\n",
    "            print('\\t' + str(sync_blobs).replace('\\n', '\\n\\t'))\n",
    "\n",
    "        # Save data\n",
    "        valid_data = server.clients[ID].synchronizer.add_data(undistorted_blobs, PTS)\n",
    "\n",
    "        if verbose: \n",
    "            if valid_data:\n",
    "                print('\\tData Accepted!')\n",
    "            else:\n",
    "                print('\\tData Refused!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Blobs to Markers\n",
    "\n",
    "For the Fundamental Matrix estimation algorithm to work, points must be matched from an image to another. \n",
    "\n",
    "Since the Fundamental Matrix is still not known, it means the points cannot be ordered by epipolar lines. \n",
    "\n",
    "To work around that, the markers in the scene will be arranged in a collinear pattern, where the distance between adjacent markers in the line will be in an arbitrary non-unit ratio.\n",
    "\n",
    "The reason for they to be collinear is the fact that in an undistorted image the distance ratio between the detected blobs will still be the same, but in pixels.\n",
    "\n",
    "The ratio will make it possible to label each blob to each marker. The below algorithm will order the blobs according to the ratio in the following order:\n",
    "1. The closest blob to the middle blob (Named A);\n",
    "2. The middle blob (Named B);\n",
    "3. The furthest blob from the middle blob (Named C);\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collinear_order(blobs, ratio):\n",
    "    # Distances between blobs\n",
    "    distances = np.array([np.linalg.norm(blobs[0] - blobs[1]), \n",
    "                          np.linalg.norm(blobs[1] - blobs[2]), \n",
    "                          np.linalg.norm(blobs[2] - blobs[0])])\n",
    "    \n",
    "    # Shortest distance\n",
    "    shortest = np.min(distances)\n",
    "\n",
    "    # If x is invalid\n",
    "    if shortest == 0.0 or shortest is np.nan:\n",
    "        return None\n",
    "\n",
    "    # Normalize distances\n",
    "    distances /= shortest\n",
    "\n",
    "    # Measured unique distance sums\n",
    "    measured_unique_sums = np.array([distances[0] + distances[2],\n",
    "                                     distances[0] + distances[1],\n",
    "                                     distances[1] + distances[2]])\n",
    "    \n",
    "    # Exprected unique distance sums\n",
    "    expected_unique_sums = np.array([ratio[0] + ratio[0] + ratio[1],\n",
    "                                     ratio[0] + ratio[1],\n",
    "                                     ratio[0] + ratio[1] + ratio[1]])\n",
    "    \n",
    "    # Error matrix\n",
    "    difference_matrix = np.array([[np.abs(measured - expected)\n",
    "                                   for measured in measured_unique_sums] \n",
    "                                   for expected in expected_unique_sums])\n",
    "\n",
    "    # Using the hungarian (Munkres) assignment algorithm to find unique correspondences between blobs and epilines\n",
    "    _, new_indices = linear_sum_assignment(difference_matrix)\n",
    "\n",
    "    return blobs[new_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Back a Camera's Feed\n",
    "\n",
    "The following cell will replicate a real time camera feed of the simulation. Change the `ID` parameter to switch between camera views.\n",
    "\n",
    "In this case, the blob labelling will be shown in the feed to check if the ordering algorithm is working as expected.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playback a camera image feed in fidelity time\n",
    "playback = False\n",
    "\n",
    "if playback:\n",
    "    ID = 0 # Camera ID to be watched\n",
    "        \n",
    "    # Converting to np arrays\n",
    "    sync_PTS = np.array(server.clients[ID].synchronizer.sync_PTS)\n",
    "    sync_blobs = np.array(server.clients[ID].synchronizer.sync_blobs)\n",
    "    \n",
    "    # Generating frames\n",
    "    images = []\n",
    "    for PTS, blobs in zip(sync_PTS, sync_blobs):\n",
    "        image = np.zeros(server.clients[ID].camera.resolution)\n",
    "        image = cv2.putText(image, str(PTS), \n",
    "                                    [40, 40], \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                    1, \n",
    "                                    (255, 0, 0), \n",
    "                                    1, \n",
    "                                    cv2.LINE_AA)\n",
    "\n",
    "        ordered_blobs = collinear_order(blobs, (1, 2))\n",
    "\n",
    "        if ordered_blobs is not None:\n",
    "            for tag, blob in zip(['A', 'B', 'C'], ordered_blobs):\n",
    "\n",
    "                image = cv2.putText(image, tag, \n",
    "                                    blob.astype(int), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                    0.5, \n",
    "                                    (255, 255, 255), \n",
    "                                    1, \n",
    "                                    cv2.LINE_AA)\n",
    "            \n",
    "        images.append(image)\n",
    "\n",
    "    # Getting delay between each frame\n",
    "    delays = sync_PTS[1:] - sync_PTS[:-1]\n",
    "\n",
    "    # Playing the animation\n",
    "    for delay, image in zip(delays, images):\n",
    "        cv2.imshow(f'Camera {ID} Feed', image)\n",
    "        cv2.waitKey(int(1e3 * delay))\n",
    "\n",
    "    # Closing all open windows \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Relative Poses\n",
    "\n",
    "Having the measured 3D distances between each markers, for each pair, \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizePoints(pts):\n",
    "    # Calculate origin centroid\n",
    "    center = np.mean(pts,axis=0)\n",
    "\n",
    "    # Translate points to centroid\n",
    "    traslatedPts = pts - center\n",
    "\n",
    "    # Calculate scale for the average point to be (1,1,1) >> homogeneous\n",
    "    meanDist2Center = np.mean(np.linalg.norm(traslatedPts,axis=1))\n",
    "    if meanDist2Center: # Protect against division by zero\n",
    "        scale = np.sqrt(2)/meanDist2Center\n",
    "    else:\n",
    "        return pts, 0, False\n",
    "    \n",
    "    # Compute translation matrix >> (x-x_c)*scale\n",
    "    T = np.diag((scale,scale,1))\n",
    "    T[0:2,2] = -scale*center\n",
    "\n",
    "    # Transform in homogeneous coordinates\n",
    "    homogeneousPts = np.vstack((pts.T,np.ones((1,pts.shape[0]))))\n",
    "    normPoints = np.matmul(T,homogeneousPts)\n",
    "\n",
    "    return normPoints, T, True\n",
    "\n",
    "def singularValueDecomposition(matrix):\n",
    "    leftSingVectors, singValues, rightSingVectorsTransposed = np.linalg.svd(matrix)\n",
    "    singValuesMatrix = np.zeros((3, 3))\n",
    "    \n",
    "    np.fill_diagonal(singValuesMatrix, singValues)\n",
    "    rightSingVectors = rightSingVectorsTransposed.T.conj() \n",
    "    \n",
    "    return leftSingVectors, singValuesMatrix, rightSingVectors\n",
    "\n",
    "def reprojectionError(F,pts1,pts2):  # pts are Nx3 array of homogenous coordinates.  \n",
    "    # How well F satisfies the equation pt1 * F * pt2 == 0\n",
    "    vals = np.matmul(pts2.T,np.matmul(F,pts1))\n",
    "    err = np.abs(vals)\n",
    "    \n",
    "    return np.mean(err)\n",
    "\n",
    "def estimateFundMatrix_8norm(pts1,pts2,verbose=False):\n",
    "    # Get number of matched points\n",
    "    numPoints = pts1.shape[0]\n",
    "    \n",
    "    # Transform to normalized points\n",
    "    normPts1,t1,valid1 = normalizePoints(pts1) \n",
    "    normPts2,t2,valid2 = normalizePoints(pts2)\n",
    "    if valid1 and valid2:\n",
    "        # Construct A matrix for 8-norm: Zisserman (pg. 279)\n",
    "        A = np.zeros((numPoints,9))\n",
    "        for i in range(numPoints):\n",
    "            pt1 = normPts1[:,i]\n",
    "            pt2 = normPts2[:,i]\n",
    "            A[i] = [pt1[0]*pt2[0], pt1[1]*pt2[0], pt2[0],\n",
    "                    pt1[0]*pt2[1], pt1[1]*pt2[1], pt2[1],\n",
    "                           pt1[0],        pt1[1],      1]\n",
    "\n",
    "        # F is the smallest singular value of A\n",
    "        _,_,V = singularValueDecomposition(A)\n",
    "        F = V[:, -1].reshape(3,3)\n",
    "        U,D,V = singularValueDecomposition(F)\n",
    "        D[-1,-1] = 0\n",
    "        F = np.matmul(np.matmul(U,D),V.T)\n",
    "\n",
    "        # Transform F back to the original scale\n",
    "        \n",
    "        F = np.matmul(np.matmul(t2.T,F),t1)\n",
    "        \n",
    "        # Normalise F\n",
    "        F = F/np.linalg.norm(F)\n",
    "        if F[-1,-1] < 0: \n",
    "            F = -F\n",
    "\n",
    "        if verbose:\n",
    "            reprojectionError(F,np.vstack((pts1.T,np.ones((1,pts1.shape[0])))),np.vstack((pts2.T,np.ones((1,pts2.shape[0])))))\n",
    "        return F,True\n",
    "    else:\n",
    "        return 0,False\n",
    "    \n",
    "def decomposeEssentialMat(E,K1,K2,pts1,pts2):\n",
    "    U,D,V = singularValueDecomposition(E)\n",
    "    e = (D[0][0]+D[1][1])/2\n",
    "    D = np.diag([e,e,0])\n",
    "    E_aux = np.matmul(np.matmul(U,D),V.T)\n",
    "    U,_,V = singularValueDecomposition(E_aux)\n",
    "    W = np.array([[0,-1,0],[1,0,0],[0,0,1]])\n",
    "    Z = [[0,1,0],[-1,0,0],[0,0,0]]\n",
    "    R1 = np.matmul(np.matmul(U,W),V.T)\n",
    "    R2 = np.matmul(np.matmul(U,W.T),V.T)\n",
    "\n",
    "    if np.linalg.det(R1) < 0: \n",
    "        R1 = -R1\n",
    "    if np.linalg.det(R2) < 0: \n",
    "        R2 = -R2\n",
    "\n",
    "    Tx = np.matmul(np.matmul(U,Z),U.T)\n",
    "    t = np.array([Tx[2][1],Tx[0][2],Tx[1,0]])\n",
    "\n",
    "    Rs = np.concatenate((R1,R1,R2,R2)).reshape(-1,3,3)\n",
    "    Ts = np.concatenate((t,-t,t,-t)).reshape(-1,1,3)\n",
    "\n",
    "    numNegatives = np.zeros((Ts.shape[0],1))\n",
    "    numPoints = pts1.shape[0]\n",
    "    P1 = np.hstack((K1,[[0.],[0.],[0.]]))\n",
    "\n",
    "    for i in range(0,Ts.shape[0]):\n",
    "        P2 = np.matmul(K2,np.hstack((Rs[i],Ts[i].T)))\n",
    "        M1,M2 = P1[0:3, 0:3],P2[0:3, 0:3]\n",
    "        c1,c2 = np.matmul(-np.linalg.inv(M1),P1[0:3,3]),np.matmul(-np.linalg.inv(M2),P2[0:3,3])\n",
    "        u1,u2 = np.vstack((pts1.T,np.ones((1,numPoints)))),np.vstack((pts2.T,np.ones((1,numPoints))))\n",
    "        a1,a2 = np.matmul(np.linalg.inv(M1),u1),np.matmul(np.linalg.inv(M2),u2)\n",
    "        points3D,y = np.zeros((numPoints,3)),c2 - c1\n",
    "\n",
    "        for k in range(0,numPoints):\n",
    "            A = np.hstack((a1[:,k].reshape(3,1),-a2[:,k].reshape(3,1)))\n",
    "            alpha = np.matmul(np.linalg.pinv(A),y)\n",
    "            p = (c1 + alpha[0] * a1[:,k] + c2 + alpha[1] * a2[:,k]) / 2\n",
    "            points3D[k,:] = p\n",
    "\n",
    "        m1 = points3D\n",
    "        m2 = np.add(np.matmul(m1,Rs[i].T),np.tile(Ts[i],(numPoints,1)))\n",
    "        numNegatives[i] = np.sum((m1[:,2] < 0) | (m2[:,2] < 0));\n",
    "\n",
    "    idx = numNegatives.argmin()\n",
    "    \n",
    "    R = Rs[idx]\n",
    "    \n",
    "    t = Ts[idx]\n",
    "    if numNegatives.min() > 0:\n",
    "        print('[ERROR] no valid rotation matrix')\n",
    "        return np.NaN,np.NaN\n",
    "    \n",
    "    return R, t.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_essential_matrix(E, \n",
    "                      blobs_reference, \n",
    "                      blobs_auxiliary, \n",
    "                      intrinsic_matrix_reference, \n",
    "                      intrinsic_matrix_auxiliary):\n",
    "    \n",
    "    # Decompose the essential matrix\n",
    "    R1, R2, t = cv2.decomposeEssentialMat(E)\n",
    "    \n",
    "    # Possible rotations and translations for the auxiliary camera\n",
    "    R_t_options = [[R1,  t],\n",
    "                   [R1, -t],\n",
    "                   [R2,  t],\n",
    "                   [R2, -t]]\n",
    "    \n",
    "    best_option = None\n",
    "\n",
    "    # Projection matrix of the first camera\n",
    "    P_reference = intrinsic_matrix_reference @ np.hstack((np.eye(3), np.zeros((3, 1))))\n",
    "    \n",
    "    # Triangulate points and check their validity\n",
    "    for option, R_t in enumerate(R_t_options):\n",
    "        P_auxiliary = intrinsic_matrix_auxiliary @ np.hstack(R_t)\n",
    "\n",
    "        triangulated_points_4D = cv2.triangulatePoints(P_reference.astype(np.float32), \n",
    "                                                       P_auxiliary.astype(np.float32), \n",
    "                                                       blobs_reference.T.astype(np.float32), \n",
    "                                                       blobs_auxiliary.T.astype(np.float32))\n",
    "        \n",
    "        # Normalize homogeneous coordinates and discard last row\n",
    "        triangulated_points_3D = (triangulated_points_4D / triangulated_points_4D[-1])[:-1, :]\n",
    "\n",
    "        # Count how many points have a positive z-coordinate \n",
    "        # This indicates if the point is in front of the camera or not\n",
    "        frontal_points = np.count_nonzero(triangulated_points_3D[2] > 0)\n",
    "\n",
    "        # No markers were shot behind the cameras\n",
    "        if frontal_points == triangulated_points_3D.shape[1]:\n",
    "            best_option = option # Where all points are frontal points\n",
    "\n",
    "    # No valid decomposition\n",
    "    if best_option is None:\n",
    "        return None, None \n",
    "    \n",
    "    # Valid decomposition\n",
    "    return R_t_options[best_option]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair (0, 1):\n",
      "> Euclidean Distance to Ground Truth = 4.12409e-17\n",
      "> K = 5.02869\n",
      "> Measured AB = 0.05001 | Std deviation = 0.00166\n",
      "> Measured BC = 0.10008 | Std deviation = 0.00216\n",
      "> Measured AC = 0.15001 | Std deviation = 0.00279\n",
      "\n",
      "Pair (0, 2):\n",
      "> Euclidean Distance to Ground Truth = 6.38906e-17\n",
      "> K = 7.08613\n",
      "> Measured AB = 0.05014 | Std deviation = 0.00206\n",
      "> Measured BC = 0.10004 | Std deviation = 0.00307\n",
      "> Measured AC = 0.15007 | Std deviation = 0.00414\n",
      "\n",
      "Pair (0, 3):\n",
      "> Euclidean Distance to Ground Truth = 1.58494e-16\n",
      "> K = 5.01886\n",
      "> Measured AB = 0.05004 | Std deviation = 0.00184\n",
      "> Measured BC = 0.10005 | Std deviation = 0.00238\n",
      "> Measured AC = 0.15002 | Std deviation = 0.00314\n",
      "\n",
      "Pair (1, 0):\n",
      "> Euclidean Distance to Ground Truth = 4.12409e-17\n",
      "> K = 5.02868\n",
      "> Measured AB = 0.05001 | Std deviation = 0.00166\n",
      "> Measured BC = 0.10008 | Std deviation = 0.00216\n",
      "> Measured AC = 0.15001 | Std deviation = 0.00279\n",
      "\n",
      "Pair (1, 2):\n",
      "> Euclidean Distance to Ground Truth = 1.50634e-16\n",
      "> K = 5.01751\n",
      "> Measured AB = 0.05009 | Std deviation = 0.00173\n",
      "> Measured BC = 0.09999 | Std deviation = 0.00231\n",
      "> Measured AC = 0.15003 | Std deviation = 0.00301\n",
      "\n",
      "Pair (1, 3):\n",
      "> Euclidean Distance to Ground Truth = 7.84468e-18\n",
      "> K = 7.08099\n",
      "> Measured AB = 0.04995 | Std deviation = 0.00189\n",
      "> Measured BC = 0.10014 | Std deviation = 0.00238\n",
      "> Measured AC = 0.15001 | Std deviation = 0.00262\n",
      "\n",
      "Pair (2, 0):\n",
      "> Euclidean Distance to Ground Truth = 6.38906e-17\n",
      "> K = 7.08610\n",
      "> Measured AB = 0.05014 | Std deviation = 0.00206\n",
      "> Measured BC = 0.10004 | Std deviation = 0.00307\n",
      "> Measured AC = 0.15007 | Std deviation = 0.00414\n",
      "\n",
      "Pair (2, 1):\n",
      "> Euclidean Distance to Ground Truth = 1.50634e-16\n",
      "> K = 5.01750\n",
      "> Measured AB = 0.05009 | Std deviation = 0.00173\n",
      "> Measured BC = 0.09999 | Std deviation = 0.00231\n",
      "> Measured AC = 0.15003 | Std deviation = 0.00301\n",
      "\n",
      "Pair (2, 3):\n",
      "> Euclidean Distance to Ground Truth = 6.94252e-17\n",
      "> K = 5.00277\n",
      "> Measured AB = 0.05012 | Std deviation = 0.00184\n",
      "> Measured BC = 0.10000 | Std deviation = 0.00260\n",
      "> Measured AC = 0.15000 | Std deviation = 0.00294\n",
      "\n",
      "Pair (3, 0):\n",
      "> Euclidean Distance to Ground Truth = 1.58494e-16\n",
      "> K = 5.01885\n",
      "> Measured AB = 0.05004 | Std deviation = 0.00184\n",
      "> Measured BC = 0.10005 | Std deviation = 0.00238\n",
      "> Measured AC = 0.15002 | Std deviation = 0.00314\n",
      "\n",
      "Pair (3, 1):\n",
      "> Euclidean Distance to Ground Truth = 7.84468e-18\n",
      "> K = 7.08100\n",
      "> Measured AB = 0.04995 | Std deviation = 0.00189\n",
      "> Measured BC = 0.10014 | Std deviation = 0.00238\n",
      "> Measured AC = 0.15001 | Std deviation = 0.00263\n",
      "\n",
      "Pair (3, 2):\n",
      "> Euclidean Distance to Ground Truth = 6.94252e-17\n",
      "> K = 5.00277\n",
      "> Measured AB = 0.05012 | Std deviation = 0.00184\n",
      "> Measured BC = 0.10000 | Std deviation = 0.00260\n",
      "> Measured AC = 0.15000 | Std deviation = 0.00294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Measured distances between markers\n",
    "# Distances: [AB, BC, AC]\n",
    "measured_distances = np.array([5e-2, 10e-2, 15e-2]) # In meters\n",
    "\n",
    "# All possible camera pairs\n",
    "client_ids = np.arange(n_clients)\n",
    "pairs = [(i, j) for i in client_ids for j in client_ids[client_ids != i]] \n",
    "\n",
    "for pair in pairs:\n",
    "    # Getting data from pair\n",
    "    reference, auxiliary = pair\n",
    "    \n",
    "    # Synchronized blobs for each pair\n",
    "    sync_blobs = [server.clients[ID].synchronizer.sync_blobs for ID in pair]\n",
    "    \n",
    "    # Order collinear blobs\n",
    "    ordered_blobs_reference = []\n",
    "    ordered_blobs_auxiliary = []\n",
    "\n",
    "    for same_PTS_blobs in zip(*sync_blobs):\n",
    "        blobs_reference = collinear_order(same_PTS_blobs[0], (1, 2))\n",
    "        blobs_auxiliary = collinear_order(same_PTS_blobs[1], (1, 2))\n",
    "\n",
    "        if blobs_reference is None or blobs_auxiliary is None:\n",
    "            continue\n",
    "\n",
    "        ordered_blobs_reference.append(blobs_reference)\n",
    "        ordered_blobs_auxiliary.append(blobs_auxiliary)\n",
    "\n",
    "    ordered_blobs_reference = np.array(ordered_blobs_reference)\n",
    "    ordered_blobs_auxiliary = np.array(ordered_blobs_auxiliary)\n",
    "\n",
    "    # Join all ordered blobs in a single matrix\n",
    "    all_blobs_reference = np.vstack(ordered_blobs_reference)\n",
    "    all_blobs_auxiliary = np.vstack(ordered_blobs_auxiliary)\n",
    "    \n",
    "    # Ground truth fundamental matrix\n",
    "    F_ground_truth = server.multiple_view.fundamental_matrix[reference][auxiliary]\n",
    "\n",
    "    F_estimated, mask = cv2.findFundamentalMat(points1=all_blobs_reference, \n",
    "                                        points2=all_blobs_auxiliary, \n",
    "                                        method=cv2.FM_8POINT)\n",
    "\n",
    "    print(f'Pair {pair}:')\n",
    "    print(f'> Euclidean Distance to Ground Truth = {np.abs(np.linalg.det(F_ground_truth - F_estimated)):.5e}')\n",
    "\n",
    "    # Selecting inlier points    \n",
    "    inlier_all_blobs_reference = all_blobs_reference[mask.ravel() == 1]\n",
    "    inlier_all_blobs_auxiliary = all_blobs_auxiliary[mask.ravel() == 1]\n",
    "\n",
    "    mask = np.array([np.prod(flags) for flags in mask.reshape(-1, 3)])\n",
    "\n",
    "    inlier_blobs_reference = ordered_blobs_reference[mask == 1]\n",
    "    inlier_blobs_auxiliary = ordered_blobs_auxiliary[mask == 1]\n",
    "\n",
    "    # Calculating essential matrix\n",
    "    E = server.clients[auxiliary].camera.intrinsic_matrix.T @ F_estimated @ server.clients[reference].camera.intrinsic_matrix\n",
    "\n",
    "    # Decomposing essential matrix\n",
    "    R, t = decompose_essential_matrix(E,\n",
    "                                      inlier_all_blobs_reference,\n",
    "                                      inlier_all_blobs_auxiliary,\n",
    "                                      server.clients[reference].camera.intrinsic_matrix,\n",
    "                                      server.clients[auxiliary].camera.intrinsic_matrix)\n",
    "\n",
    "    # Check if decomposition worked\n",
    "    if R is None and t is None:\n",
    "        print('> No valid decomposition!')\n",
    "        continue\n",
    "\n",
    "    object_matrix_auxiliary = np.hstack((R, t))\n",
    "    extrinsic_matrix_auxiliary = np.linalg.inv(build_extrinsic_matrix(object_matrix_auxiliary))\n",
    "\n",
    "    # Calculating projection matrices\n",
    "    # The reference camera will be the reference frame, thus the identity matrix\n",
    "    P_reference = build_projection_matrix(intrinsic_matrix=server.clients[reference].camera.intrinsic_matrix, \n",
    "                                          extrinsic_matrix=np.eye(4)) \n",
    "    \n",
    "    P_auxiliary = build_projection_matrix(intrinsic_matrix=server.clients[auxiliary].camera.intrinsic_matrix, \n",
    "                                          extrinsic_matrix=extrinsic_matrix_auxiliary)\n",
    "    \n",
    "    # List of all measured distance\n",
    "    all_unscaled_distances = []\n",
    "\n",
    "    # Scale factor for each triangulated frame\n",
    "    K = []\n",
    "\n",
    "    for points_reference_PTS, points_auxiliary_PTS in zip(inlier_blobs_reference, inlier_blobs_auxiliary):\n",
    "        triangulated_points_4D = cv2.triangulatePoints(P_reference.astype(np.float32), \n",
    "                                                       P_auxiliary.astype(np.float32), \n",
    "                                                       points_reference_PTS.T.astype(np.float32), \n",
    "                                                       points_auxiliary_PTS.T.astype(np.float32))\n",
    "        \n",
    "        # Normalize homogeneous coordinates and discard last row\n",
    "        triangulated_points_3D = (triangulated_points_4D / triangulated_points_4D[-1])[:-1, :].T\n",
    "\n",
    "        # Unscaled distances\n",
    "        unscaled_distances = np.array([np.linalg.norm(triangulated_points_3D[0] - triangulated_points_3D[1]),\n",
    "                                       np.linalg.norm(triangulated_points_3D[1] - triangulated_points_3D[2]),\n",
    "                                       np.linalg.norm(triangulated_points_3D[0] - triangulated_points_3D[2])])\n",
    "\n",
    "        # Save values\n",
    "        all_unscaled_distances.append(unscaled_distances)\n",
    "\n",
    "        # Appending scale factors\n",
    "        K.append(np.sum(measured_distances) / np.sum(unscaled_distances))\n",
    "\n",
    "    # Mean scale factor\n",
    "    K_mean = np.mean(np.array(K))\n",
    "    print(f'> K = {K_mean:.5f}')\n",
    "\n",
    "    # Data analysis\n",
    "    unscaled_distances_mean = np.mean(np.array(all_unscaled_distances), axis=0)\n",
    "    scaled_distances_mean = unscaled_distances_mean * K_mean\n",
    "\n",
    "    unscaled_distances_std = np.std(np.array(all_unscaled_distances), axis=0)\n",
    "    scaled_distances_std = unscaled_distances_std * K_mean\n",
    "\n",
    "    print(f'> Measured AB = {scaled_distances_mean[0]:.5f} | Std deviation = {scaled_distances_std[0]:.5f}')\n",
    "    print(f'> Measured BC = {scaled_distances_mean[1]:.5f} | Std deviation = {scaled_distances_std[1]:.5f}')\n",
    "    print(f'> Measured AC = {scaled_distances_mean[2]:.5f} | Std deviation = {scaled_distances_std[2]:.5f}')\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Compute epipolar lines\\nepilines_reference = cv2.computeCorrespondEpilines(points=all_points_auxiliary, \\n                                                   whichImage=2, \\n                                                   F=F_estimated).reshape(-1,3)\\n\\nepilines_auxiliary = cv2.computeCorrespondEpilines(points=all_points_reference, \\n                                                   whichImage=1, \\n                                                   F=F_estimated).reshape(-1,3)\\n                                                   \\n# Create the image viewer\\nplot_reference = Viewer2D(title='Coppelia's Reference Vision Sensor', \\n                          resolution=server.clients[reference].camera.resolution, \\n                          image=np.zeros(server.clients[reference].camera.resolution),\\n                          graphical=True)\\n\\n# Adding the blob centroids to the image\\nplot_reference.add_points(points=all_points_reference.T, \\n                          name='Blob Centroids', \\n                          color='white')\\n\\n# Draw epipolar lines to image\\nplot_reference.add_lines(lines=epilines_reference, \\n                         name='Epipolar Lines')\\n\\n# Plot image\\nplot_reference.figure.show(renderer='notebook_connected')\\n\\n# Create the image viewer\\nplot_auxiliary = Viewer2D(title='Coppelia's Auxiliary Vision Sensor', \\n                          resolution=server.clients[auxiliary].camera.resolution, \\n                          image=np.zeros(server.clients[auxiliary].camera.resolution),\\n                          graphical=True)\\n\\n# Adding the blob centroids to the image\\nplot_auxiliary.add_points(points=all_points_auxiliary.T, \\n                          name='Blob Centroids', \\n                          color='white')\\n\\n# Draw epipolar lines to image\\nplot_auxiliary.add_lines(lines=epilines_auxiliary, \\n                         name='Epipolar Lines')\\n\\n# Plot image\\nplot_auxiliary.figure.show(renderer='notebook_connected')\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Compute epipolar lines\n",
    "epilines_reference = cv2.computeCorrespondEpilines(points=all_points_auxiliary, \n",
    "                                                   whichImage=2, \n",
    "                                                   F=F_estimated).reshape(-1,3)\n",
    "\n",
    "epilines_auxiliary = cv2.computeCorrespondEpilines(points=all_points_reference, \n",
    "                                                   whichImage=1, \n",
    "                                                   F=F_estimated).reshape(-1,3)\n",
    "                                                   \n",
    "# Create the image viewer\n",
    "plot_reference = Viewer2D(title='Coppelia\\'s Reference Vision Sensor', \n",
    "                          resolution=server.clients[reference].camera.resolution, \n",
    "                          image=np.zeros(server.clients[reference].camera.resolution),\n",
    "                          graphical=True)\n",
    "\n",
    "# Adding the blob centroids to the image\n",
    "plot_reference.add_points(points=all_points_reference.T, \n",
    "                          name='Blob Centroids', \n",
    "                          color='white')\n",
    "\n",
    "# Draw epipolar lines to image\n",
    "plot_reference.add_lines(lines=epilines_reference, \n",
    "                         name='Epipolar Lines')\n",
    "\n",
    "# Plot image\n",
    "plot_reference.figure.show(renderer='notebook_connected')\n",
    "\n",
    "# Create the image viewer\n",
    "plot_auxiliary = Viewer2D(title='Coppelia\\'s Auxiliary Vision Sensor', \n",
    "                          resolution=server.clients[auxiliary].camera.resolution, \n",
    "                          image=np.zeros(server.clients[auxiliary].camera.resolution),\n",
    "                          graphical=True)\n",
    "\n",
    "# Adding the blob centroids to the image\n",
    "plot_auxiliary.add_points(points=all_points_auxiliary.T, \n",
    "                          name='Blob Centroids', \n",
    "                          color='white')\n",
    "\n",
    "# Draw epipolar lines to image\n",
    "plot_auxiliary.add_lines(lines=epilines_auxiliary, \n",
    "                         name='Epipolar Lines')\n",
    "\n",
    "# Plot image\n",
    "plot_auxiliary.figure.show(renderer='notebook_connected')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
