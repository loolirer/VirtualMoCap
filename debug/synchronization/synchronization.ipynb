{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCap Arena\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules...\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.interpolate import CubicSpline\n",
    "import cv2\n",
    "import socket\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..') # Go back to base directory\n",
    "\n",
    "from modules.vision.camera import Camera\n",
    "from modules.vision.multiple_view import MultipleView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instanciating Multiple View Object\n",
    "\n",
    "To generate the data regarding the mathematical model of multiple vision triangulation in *CoppeliaSim*, it will be instanciated a Multiple View Object, composed of a set of Camera Obejcts that matches the Vision Sensors' parameters. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clients = 4\n",
    "cameras = [] # Camera objects list\n",
    "\n",
    "# Object matrix of Camera 0\n",
    "base_matrix = np.array([[-7.07106781e-01,  5.00000000e-01, -5.00000000e-01, 2.50000000e+00],\n",
    "                        [ 7.07106781e-01,  5.00000000e-01, -5.00000000e-01, 2.50000000e+00],\n",
    "                        [ 1.46327395e-13, -7.07106781e-01, -7.07106781e-01, 2.50000000e+00]])\n",
    "\n",
    "for ID in range(n_clients):\n",
    "    # Spread all cameras uniformely in a circle around the arena\n",
    "    R = np.array(sp.spatial.transform.Rotation.from_euler('z', (360 / n_clients) * ID, degrees=True).as_matrix())\n",
    "    object_matrix = R @ base_matrix\n",
    "\n",
    "    cameras.append(Camera(# Intrinsic Parameters\n",
    "                          resolution=(720,720), \n",
    "                          fov_degrees=60.0,     \n",
    "          \n",
    "                          # Extrinsic Parameters\n",
    "                          object_matrix=object_matrix\n",
    "          \n",
    "                          # Rational Lens Distortion Model\n",
    "                          # distortion_model='rational',\n",
    "                          # distortion_coefficients=np.array([0.014, -0.003, -0.0002, -0.000003, 0.0009, 0.05, -0.007, 0.0017]), \n",
    "                          \n",
    "                          # Fisheye Lens Distortion Model\n",
    "                          # distortion_model='fisheye',\n",
    "                          # distortion_coefficients=np.array([0.395, 0.633, -2.417, 2.110]),\n",
    "          \n",
    "                          # Image Noise Model\n",
    "                          # snr_dB=13\n",
    "                          ))\n",
    "    \n",
    "multiple_view = MultipleView(cameras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Server's UDP Socket\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Creating socket...\n",
      "[SERVER] Socket successfully created\n",
      "[SERVER] Bound to port 8888\n"
     ]
    }
   ],
   "source": [
    "print(f'[SERVER] Creating socket...')\n",
    "\n",
    "# Try to create server socket\n",
    "try: \n",
    "    server_socket = socket.socket(socket.AF_INET,    # Internet\n",
    "                                  socket.SOCK_DGRAM) # UDP\n",
    "    print(f'[SERVER] Socket successfully created')\n",
    "    \n",
    "except socket.error as err: \n",
    "    print(f'[SERVER] Socket creation failed with error {err}\\n')\n",
    "    print(f'[SERVER] Quitting code...')\n",
    "    exit()\n",
    "\n",
    "server_ip = '127.0.0.1' # Server IP\n",
    "server_port = 8888      # Server Port\n",
    "server_address = (server_ip, server_port) \n",
    "\n",
    "server_socket.bind(server_address)\n",
    "print(f'[SERVER] Bound to port {server_port}')\n",
    "\n",
    "buffer_size = 1024 # Size of the messages in bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring the Controller's UDP Socket\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controller socket info\n",
    "controller_ip = '127.0.0.1' # Controller IP\n",
    "controller_port = 7777      # Controller Port\n",
    "controller_address = (controller_ip, controller_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending Capture Info\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Capture info sent\n",
      "[SERVER] Clients created\n"
     ]
    }
   ],
   "source": [
    "simulation_time = 10 # In seconds\n",
    "\n",
    "# Send capture info to the controller\n",
    "message = f'{n_clients}, {simulation_time}'\n",
    "\n",
    "message_bytes = message.encode()\n",
    "\n",
    "server_socket.sendto(message_bytes, controller_address)\n",
    "print(f'[SERVER] Capture info sent')\n",
    "\n",
    "# Wait for controller to setup the info\n",
    "server_socket.recvfrom(buffer_size)\n",
    "print(f'[SERVER] Clients created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending Vision Sensor Parameters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Sending Vision Sensors' parameters\n",
      "\tVision Sensor 0 created\n",
      "\tVision Sensor 1 created\n",
      "\tVision Sensor 2 created\n",
      "\tVision Sensor 3 created\n"
     ]
    }
   ],
   "source": [
    "def coppelia_vision_sensor_wrapper(camera):\n",
    "    parameter_array = np.array([# Options\n",
    "                                2+4, # Bit 1 set: Perspective Mode\n",
    "                                     # Bit 2 set: Invisible Viewing Frustum \n",
    "                                                                     \n",
    "                                # Integer parameters\n",
    "                                camera.resolution[0], \n",
    "                                camera.resolution[1],\n",
    "                                0, # Reserved\n",
    "                                0, # Reserved\n",
    "\n",
    "                                # Float parameters\n",
    "                                0.01, # Near clipping plane in meters\n",
    "                                10, # Far clipping plane in meters\n",
    "                                camera.fov_radians, # FOV view angle in radians\n",
    "                                0.1, # Sensor X size\n",
    "                                0.0, # Reserved\n",
    "                                0.0, # Reserved\n",
    "                                0.0, # Null pixel red-value\n",
    "                                0.0, # Null pixel green-value\n",
    "                                0.0, # Null pixel blue-value\n",
    "                                0.0, # Reserved\n",
    "                                0.0, # Reserved\n",
    "                                ], \n",
    "                               dtype=np.float64)\n",
    "\n",
    "    transformation_array = camera.coppeliasim_object_matrix.ravel()\n",
    "    \n",
    "    buffer = np.concatenate((parameter_array, transformation_array)).tobytes()\n",
    "\n",
    "    return buffer\n",
    "\n",
    "print(f'[SERVER] Sending Vision Sensors\\' parameters')\n",
    "\n",
    "for ID, C in enumerate(multiple_view.cameras):\n",
    "    # Wrap vision sensor parameters\n",
    "    buffer = coppelia_vision_sensor_wrapper(C)\n",
    "\n",
    "    server_socket.sendto(buffer, controller_address)\n",
    "\n",
    "    # Wait for controller to setup the info\n",
    "    server_socket.recvfrom(buffer_size)\n",
    "    print(f'\\tVision Sensor {ID} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sending trigger\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Scene ready\n",
      "[SERVER] Trigger sent!\n"
     ]
    }
   ],
   "source": [
    "# Wait for controller to setup the scene\n",
    "server_socket.recvfrom(buffer_size)\n",
    "print(f'[SERVER] Scene ready')\n",
    "\n",
    "# Send trigger\n",
    "server_socket.sendto(''.encode(), controller_address)\n",
    "print(f'[SERVER] Trigger sent!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handshaking Clients\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Waiting for clients...\n",
      "\tClient 0 connected\n",
      "\tClient 1 connected\n",
      "\tClient 2 connected\n",
      "\tClient 3 connected\n",
      "[SERVER] All clients connected!\n"
     ]
    }
   ],
   "source": [
    "client_addresses = {}\n",
    "\n",
    "print(f'[SERVER] Waiting for clients...')\n",
    "\n",
    "# Address lookup \n",
    "while len(client_addresses.keys()) < n_clients: # Until all clients are identified\n",
    "    message_bytes, address = server_socket.recvfrom(buffer_size)\n",
    "\n",
    "    try:\n",
    "        ID = int(message_bytes.decode()) # Decode message\n",
    "\n",
    "    except: # Invalid message for decoding\n",
    "        continue # Look for another message\n",
    "\n",
    "    client_addresses[address] = ID\n",
    "\n",
    "    print(f'\\tClient {ID} connected')\n",
    "\n",
    "print(f'[SERVER] All clients connected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Data Class\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_by_proximity(previous_blobs, current_blobs):\n",
    "    ordered_current_blobs = np.empty_like(current_blobs)\n",
    "\n",
    "    for current_blob in current_blobs:\n",
    "        distances = [] # Distances from a previous blob to all current blobs\n",
    "\n",
    "        for previous_blob in previous_blobs:\n",
    "            distances.append(np.linalg.norm(previous_blob - current_blob))\n",
    "\n",
    "        new_index = np.argmin(np.array(distances)) # The match will be made for the shortest point to point distance\n",
    "\n",
    "        ordered_current_blobs[new_index] = current_blob\n",
    "\n",
    "    return ordered_current_blobs\n",
    "\n",
    "# Data structure for blob interpolation\n",
    "class CaptureData:\n",
    "    def __init__(self, \n",
    "                 n_blobs=1, # Number of expected blobs for interpolation\n",
    "                 window=10, # The minimum ammount of data points for interpolating \n",
    "                 step=0.01, # Time step for interpolation in seconds\n",
    "                 capture_time=10, # Capture time in seconds\n",
    "                 ):\n",
    "        \n",
    "        # Interpolation Parameters\n",
    "        self.n_blobs = n_blobs\n",
    "        self.interpolation_window = window\n",
    "        self.step = step\n",
    "        self.capture_time = capture_time\n",
    "        self.last_interpolation = 0\n",
    "\n",
    "        # Raw data - how it comes from the clients\n",
    "        self.raw_blobs = []\n",
    "        self.raw_PTS = []\n",
    "\n",
    "        # Interpolated data - how it should be triangulated\n",
    "        self.int_PTS = np.arange(0.0, self.capture_time, self.step)\n",
    "        self.int_blobs = np.full((self.int_PTS.size, n_blobs, 2), -1.0) \n",
    "       \n",
    "    def add_data(self, blobs, PTS):\n",
    "        # Do not add data if PTS is out of recording range\n",
    "        if PTS > self.capture_time:\n",
    "            return \n",
    "\n",
    "        # Check if it's not empty\n",
    "        if self.raw_PTS:\n",
    "            # Do not add data if PTS is already added, avoid repeated messaging\n",
    "            if PTS == self.raw_PTS[-1]:\n",
    "                return \n",
    "\n",
    "        self.raw_PTS.append(PTS)\n",
    "\n",
    "        # Ordering blobs by proximity for correct interpolation \n",
    "        if self.raw_blobs:  \n",
    "            blobs = order_by_proximity(self.raw_blobs[-1], blobs)\n",
    "\n",
    "        self.raw_blobs.append(blobs)\n",
    "\n",
    "        # Enough points to interpolate?\n",
    "        if len(self.raw_PTS) >= self.interpolation_window:\n",
    "            # Get the window last blob coordinate data\n",
    "            raw_PTS = np.array(self.raw_PTS[-self.interpolation_window:])\n",
    "            raw_blobs = np.array(self.raw_blobs[-self.interpolation_window:])\n",
    "\n",
    "            start = self.last_interpolation     # Start index of interpolated PTS  \n",
    "            end = int(raw_PTS[-1] // self.step) # Final index of interpolated PTS  \n",
    "\n",
    "            for blob in range(self.n_blobs):\n",
    "                # Extracting blob coordinate history in the interpolation window\n",
    "                # The slicing works like: raw_blob = raw_blobs[PTS, blob, axis]\n",
    "                raw_blob = raw_blobs[:, blob, :]\n",
    "\n",
    "                # Generating a cubic spline that represents blob trajectory \n",
    "                blob_trajectory = CubicSpline(raw_PTS, raw_blob)\n",
    "                \n",
    "                # Get blob tracjectory in the interpolated timestamps that are not yet interpolated\n",
    "                interpolated_blob = blob_trajectory(self.int_PTS[start:end+1]) # End of slice is exclusive!\n",
    "\n",
    "                # Add interpolated blobs to data structure\n",
    "                self.int_blobs[start:end+1, blob, :] = interpolated_blob\n",
    "\n",
    "            # Updating last interpolation to the next PTS \n",
    "            self.last_interpolation = end + 1\n",
    "\n",
    "n_blobs = 1 # Number of expected markers\n",
    "window = 3 # The minimum ammount of points for interpolating \n",
    "throughput = 20 # Triangulated scenes per second\n",
    "step = 1 / throughput \n",
    "capture_time = 10 # Total capture time\n",
    "\n",
    "capture_data = [CaptureData(n_blobs, window, step, capture_time) for _ in range(n_clients)]\n",
    "\n",
    "last_triangulation = 0\n",
    "triangulated_markers = np.empty((capture_data[0].int_PTS.size, n_blobs, 3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Simulation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SERVER] Timeout set to 5 seconds\n",
      "\n",
      "\n",
      "[SERVER] Timed Out!\n"
     ]
    }
   ],
   "source": [
    "verbose = False\n",
    "\n",
    "timeout = 5 # In seconds\n",
    "server_socket.settimeout(timeout) # Set server timeout\n",
    "print(f'[SERVER] Timeout set to {timeout} seconds\\n')\n",
    "\n",
    "# Breaks in the timeout\n",
    "while True: \n",
    "    # Wait for message - Event guided!\n",
    "    try:\n",
    "        message_bytes, address = server_socket.recvfrom(buffer_size)\n",
    "\n",
    "    except socket.timeout as err:\n",
    "        print('\\n[SERVER] Timed Out!')\n",
    "        \n",
    "        break # Close capture loop due to timeout\n",
    "    \n",
    "    # Check if client exists\n",
    "    try:\n",
    "        ID = client_addresses[address] # Client Identifier\n",
    "    \n",
    "    except:\n",
    "        if verbose: print('> Client not recognized')\n",
    "\n",
    "        continue # Jump to wait for the next message\n",
    "    \n",
    "    # Show sender\n",
    "    if verbose: print(f'> Received message from Client {ID} ({address[0]}, {address[1]}):')\n",
    "\n",
    "    # Decode message\n",
    "    try:\n",
    "        message = np.frombuffer(message_bytes, dtype=np.float64)\n",
    "\n",
    "    except:\n",
    "        if verbose: print('> Couldn\\'t decode message')\n",
    "\n",
    "        continue # Jump to wait for the next message\n",
    "\n",
    "    # Empty message\n",
    "    if not message.size:\n",
    "        if verbose: print(f'\\tEmpty message')\n",
    "\n",
    "        continue # Jump to wait for the next message\n",
    "\n",
    "    # Parsing message\n",
    "    PTS = message[-1] # Last element of the message contains PTS\n",
    "\n",
    "    # Valid messages only comes in 2 coordinates (u and v) per blob and the PTS\n",
    "    if message.size !=  2 * n_blobs + 1:\n",
    "\n",
    "        if message.size == 1: # Only PTS\n",
    "            if verbose: print(f'\\tNo blobs were detected - {PTS :.3f} s')\n",
    "\n",
    "        else: \n",
    "            if verbose: print(f'\\tWrong blob count or corrupted message - {PTS :.3f} s')\n",
    "\n",
    "        continue # Jump to wait for the next message\n",
    "\n",
    "    # Extracting blob centroids\n",
    "    detected_blobs = message[:-1].reshape(2, -1).T # All but last element are the blob coordinates\n",
    "\n",
    "    # Undistorting blobs\n",
    "    undistorted_blobs = multiple_view.cameras[ID].undistort_points(detected_blobs.T)          \n",
    "\n",
    "    # Print blobs\n",
    "    if verbose:\n",
    "        print(f'\\tDetected Blobs - {PTS :.3f} s')\n",
    "        print('\\t' + str(undistorted_blobs.T).replace('\\n', '\\n\\t'))\n",
    "\n",
    "    # Save data\n",
    "    capture_data[ID].add_data(undistorted_blobs.T, PTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Back the Camera's Feed\n",
    "\n",
    "The following cell will replicate a real time camera feed of the simulation. Change the `ID` parameter to switch between camera views.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playback a camera image feed in fidelity time\n",
    "ID = 0 # Camera ID to be watched\n",
    "\n",
    "for (PTS_data, blob_data, sync_type) in [(capture_data[ID].raw_PTS, capture_data[ID].raw_blobs, 'Asynchronous'), \n",
    "                                         (capture_data[ID].int_PTS, capture_data[ID].int_blobs,  'Synchronous')]:\n",
    "    \n",
    "    # Converting to np arrays\n",
    "    PTS_data = np.array(PTS_data)\n",
    "    blob_data = np.array(blob_data)\n",
    "    \n",
    "    # Generating frames\n",
    "    images = []\n",
    "    for PTS, blobs in zip(PTS_data, blob_data):\n",
    "        image = np.zeros(cameras[ID].resolution)\n",
    "\n",
    "        for blob in blobs:\n",
    "            image = cv2.circle(image, blob.astype(int), 2, 1, -1) \n",
    "            \n",
    "        images.append(image)\n",
    "\n",
    "    # Getting delay between each frame\n",
    "    delays = PTS_data[1:] - PTS_data[:-1]\n",
    "\n",
    "    # Playing the animation\n",
    "    for delay, image in zip(delays, images):\n",
    "        cv2.imshow(f'Camera {ID} - {sync_type}' , image)\n",
    "        cv2.waitKey(int(1e3 * delay))\n",
    "\n",
    "    # Closing all open windows \n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
