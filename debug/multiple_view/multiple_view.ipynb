{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules...\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../..') # Go back to base directory\n",
    "\n",
    "from modules.vision.camera import Camera\n",
    "from modules.vision.epipolar_geometry import build_essential_matrix, build_fundamental_matrix, order_centroids\n",
    "from modules.vision.blob_detection import detect_blobs\n",
    "\n",
    "from coppeliasim_zmqremoteapi_client import RemoteAPIClient\n",
    "\n",
    "# Init client \n",
    "client = RemoteAPIClient()    # Client object \n",
    "sim = client.getObject('sim') # Simulation object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cameras = 8\n",
    "camera = [] # Camera objects list\n",
    "\n",
    "for ID in range(n_cameras):\n",
    "    # Get the vision sensor handle\n",
    "    vision_sensor_handle = sim.getObject(f'/VisionSensor[{ID}]')\n",
    "\n",
    "    # Get Coppelia's 3x4 object matrix\n",
    "    object_matrix = np.array(sim.getObjectMatrix(vision_sensor_handle)).reshape((3,4))\n",
    "\n",
    "    # X and Y axis of Coppelia's Vision Sensor are inverted\n",
    "    object_matrix[:,0] *= -1 # Invert x vector column\n",
    "    object_matrix[:,1] *= -1 # Invert y vector column\n",
    "\n",
    "    camera.append(Camera(# Simulation handling\n",
    "                          vision_sensor_handle=vision_sensor_handle,\n",
    "   \n",
    "                          # Intrinsic Parameters\n",
    "                          resolution=(720,720), \n",
    "                          fov_degrees=60.0,     \n",
    "          \n",
    "                          # Extrinsic Parameters\n",
    "                          object_matrix=object_matrix,\n",
    "          \n",
    "                          # Rational Lens Distortion Model\n",
    "                          # distortion_model='rational',\n",
    "                          # distortion_coefficients=np.array([0.014, -0.003, -0.0002, -0.000003, 0.0009, 0.05, -0.007, 0.0017]),\n",
    "\n",
    "                          # Fisheye Lens Distortion Model\n",
    "                          distortion_model='fisheye',\n",
    "                          distortion_coefficients=np.array([0.395, 0.633, -2.417, 2.110]),\n",
    "          \n",
    "                          # Image Noise Model\n",
    "                          snr_dB=13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_matrix = np.array(np.zeros((n_cameras, n_cameras, 3, 3)))\n",
    "\n",
    "for reference in range(n_cameras):\n",
    "    for auxiliary in range(n_cameras):\n",
    "        if reference == auxiliary:\n",
    "            continue\n",
    "\n",
    "        E = build_essential_matrix(camera[reference].extrinsic_matrix, camera[auxiliary].extrinsic_matrix)\n",
    "\n",
    "        F = build_fundamental_matrix(camera[reference].intrinsic_matrix, camera[auxiliary].intrinsic_matrix, E)\n",
    "\n",
    "        fundamental_matrix[reference][auxiliary] = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Time Factor: 0.23198986460296125\n"
     ]
    }
   ],
   "source": [
    "# When simulation is not running, ZMQ message handling could be a bit\n",
    "# slow, since the idle loop runs at 8 Hz by default.\n",
    "# Setting the idle loop to run at full speed for this program\n",
    "defaultIdleFps = sim.getInt32Param(sim.intparam_idle_fps)   \n",
    "sim.setInt32Param(sim.intparam_idle_fps, 0)\n",
    "\n",
    "pair = (0, 1)\n",
    "reference, auxiliary = pair\n",
    "\n",
    "markers_positions = {} # Markers positions will be stored here\n",
    "\n",
    "simulation_time = 5 # In seconds\n",
    "images = {}\n",
    "\n",
    "# Simulation begins here\n",
    "sim.startSimulation()\n",
    "\n",
    "timer_start = time.time()\n",
    "\n",
    "while (t := sim.getSimulationTime()) < simulation_time:\n",
    "    # Get and save images\n",
    "    sync_images = [camera[ID].get_coppelia_image(sim.getVisionSensorCharImage) for ID in range(n_cameras)]\n",
    "    images[t] = sync_images    \n",
    "\n",
    "    # Detect blobs on the distorted image\n",
    "    distorted_blobs = [detect_blobs(image) for image in sync_images]\n",
    "\n",
    "    # If no blobs were detected then images are invalid\n",
    "    if any(blob is None for blob in distorted_blobs):\n",
    "        continue # Jump to next iteration\n",
    "\n",
    "    # Undistort blobs\n",
    "    if camera[0].distortion_model == 'rational':\n",
    "        undistorted_blobs = [cv2.undistortPoints(src=distorted_blobs[ID].T.reshape(1, -1, 2).astype(np.float32), \n",
    "                                                cameraMatrix=camera[ID].intrinsic_matrix, \n",
    "                                                distCoeffs=camera[ID].distortion_coefficients,\n",
    "                                                P=camera[ID].intrinsic_matrix).reshape(-1,2).T for ID in range(n_cameras)]\n",
    "        \n",
    "    elif camera[0].distortion_model == 'fisheye':\n",
    "        undistorted_blobs = [cv2.fisheye.undistortPoints(distorted=distorted_blobs[ID].T.reshape(1, -1, 2).astype(np.float32), \n",
    "                                                         K=camera[ID].intrinsic_matrix, \n",
    "                                                         D=camera[ID].distortion_coefficients,\n",
    "                                                         P=camera[ID].intrinsic_matrix).reshape(-1,2).T for ID in range(n_cameras)]\n",
    "\n",
    "    # Order blobs\n",
    "    epilines_auxiliary = cv2.computeCorrespondEpilines(points=undistorted_blobs[reference].T, \n",
    "                                                       whichImage=1, \n",
    "                                                       F=fundamental_matrix[reference][auxiliary]).reshape(-1,3)\n",
    "    \n",
    "    undistorted_blobs[auxiliary] = order_centroids(undistorted_blobs[auxiliary], epilines_auxiliary)\n",
    "\n",
    "    # Triangulate markers\n",
    "    triangulated_positions = cv2.triangulatePoints(camera[reference].projection_matrix.astype(float), \n",
    "                                                   camera[auxiliary].projection_matrix.astype(float), \n",
    "                                                   undistorted_blobs[reference].astype(float), \n",
    "                                                   undistorted_blobs[auxiliary].astype(float))\n",
    "    \n",
    "    # Normalize homogeneous coordinates and save\n",
    "    markers_positions[t] = (triangulated_positions / triangulated_positions[-1])[:-1, :]\n",
    "\n",
    "timer_end = time.time()\n",
    "\n",
    "# Closing all open windows \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Restore the original idle loop frequency:\n",
    "sim.setInt32Param(sim.intparam_idle_fps, defaultIdleFps)\n",
    "\n",
    "# Simulation ends here\n",
    "sim.stopSimulation()\n",
    "\n",
    "print(f'Real Time Factor: {simulation_time / (timer_end - timer_start)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Position: [-1.175 -0.975  0.1  ]\n",
      "Mean Position: [-1.17517748 -0.98312548  0.09942744]\n",
      "Triangulation Error: 8.15 mm\n",
      "Standard Deviation: 2.30 mm\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy and Precision (only works for one marker)\n",
    "all_marker_positions = None\n",
    "for frame, pts in enumerate(markers_positions.keys()):\n",
    "    if all_marker_positions is None:\n",
    "        all_marker_positions = markers_positions[pts]\n",
    "    else:\n",
    "        all_marker_positions = np.hstack((all_marker_positions, markers_positions[pts]))\n",
    "\n",
    "ground_truth_position = np.array(sim.getObjectPosition(sim.getObject('/Marker')))\n",
    "mean_position = np.mean(all_marker_positions, axis=1)\n",
    "std_dev_position = np.std(all_marker_positions, axis=1)\n",
    "\n",
    "print('Ground Truth Position:', ground_truth_position)\n",
    "print('Mean Position:', mean_position)\n",
    "print(f'Triangulation Error: {np.linalg.norm(mean_position - ground_truth_position) * 1e3 :.2f} mm')\n",
    "print(f'Standard Deviation: {np.linalg.norm(std_dev_position) * 1e3 :.2f} mm')\n",
    "\n",
    "# Playback a camera image feed in real time\n",
    "ID = 0\n",
    "timestep = int(1000 * simulation_time/len(images.keys()))\n",
    "for frame, pts in enumerate(images.keys()):\n",
    "    cv2.imshow(f'Camera {ID}', images[pts][ID])\n",
    "    cv2.waitKey(timestep)\n",
    "\n",
    "# Closing all open windows \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
